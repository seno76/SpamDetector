"""
–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –æ–±—ã—á–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ (—Å—Ç–∞—Ç—å–∏, –Ω–æ–≤–æ—Å—Ç–∏, –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞)
"""
import os
import requests
import wikipedia
from pathlib import Path
import time
import random

def download_wikipedia_articles():
    """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–µ–π –∏–∑ Wikipedia"""
    print("üìö –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–∞—Ç–µ–π –∏–∑ Wikipedia...")
    
    # –¢–µ–º—ã –¥–ª—è —Å—Ç–∞—Ç–µ–π (—Ä–∞–∑–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏ –∑–Ω–∞–Ω–∏–π)
    topics = [
        "Artificial intelligence", "Machine learning", "Python programming",
        "Data science", "Computer vision", "Natural language processing",
        "Deep learning", "Neural networks", "Statistics", "Mathematics",
        "Physics", "Chemistry", "Biology", "History", "Geography",
        "Literature", "Philosophy", "Psychology", "Economics", "Sociology",
        "Astronomy", "Geology", "Medicine", "Engineering", "Technology",
        "Music", "Art", "Architecture", "Sports", "Education",
        "Climate change", "Renewable energy", "Space exploration", "Robotics",
        "Internet", "Cybersecurity", "Blockchain", "Virtual reality",
        "Quantum computing", "Biotechnology", "Nanotechnology", "Genetics",
        "Ecology", "Agriculture", "Transportation", "Communication",
        "Linguistics", "Anthropology", "Political science", "Law"
    ]
    
    natural_dir = Path('data/raw/natural')
    natural_dir.mkdir(parents=True, exist_ok=True)
    
    downloaded = 0
    for topic in topics:
        try:
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —è–∑—ã–∫
            wikipedia.set_lang("en")
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
            page = wikipedia.page(topic)
            content = page.content
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±–æ–ª—å—à–æ–π
            if len(content) > 1000:
                filename = natural_dir / f"wiki_{topic.replace(' ', '_').lower()}.txt"
                with open(filename, 'w', encoding='utf-8') as f:
                    f.write(content)
                
                downloaded += 1
                print(f"  ‚úì {topic} ({len(content)} chars)")
                
                # –ü–∞—É–∑–∞ —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å —Å–µ—Ä–≤–µ—Ä
                time.sleep(1)
                
            if downloaded >= 50:  # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è –Ω–∞ 50 —Å—Ç–∞—Ç—å—è—Ö
                break
                
        except Exception as e:
            print(f"  ‚úó –û—à–∏–±–∫–∞ —Å '{topic}': {e}")
            continue
    
    return downloaded

def download_project_gutenberg_books():
    """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∫–Ω–∏–≥ –∏–∑ Project Gutenberg"""
    print("\nüìñ –ó–∞–≥—Ä—É–∑–∫–∞ –∫–Ω–∏–≥ –∏–∑ Project Gutenberg...")
    
    # ID –∫–Ω–∏–≥ –≤ Project Gutenberg (–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∞—è –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞)
    book_ids = [
        1342,  # Pride and Prejudice
        84,    # Frankenstein
        11,    # Alice's Adventures in Wonderland
        1661,  # The Adventures of Sherlock Holmes
        74,    # The Adventures of Tom Sawyer
        2701,  # Moby Dick
        98,    # A Tale of Two Cities
        76,    # Adventures of Huckleberry Finn
        1260,  # Jane Eyre
        2554,  # Crime and Punishment
        2600,  # War and Peace
        1080,  # A Modest Proposal
        174,   # The Picture of Dorian Gray
        768,   # Wuthering Heights
        203,   # The Souls of Black Folk
        345,   # Dracula
        5200,  # Metamorphosis
        1232,  # The Prince
        1399,  # Anne of Green Gables
        160,   # The Awakening
    ]
    
    natural_dir = Path('data/raw/natural')
    downloaded = 0
    
    for book_id in book_ids:
        try:
            url = f"https://www.gutenberg.org/files/{book_id}/{book_id}-0.txt"
            response = requests.get(url, timeout=10)
            
            if response.status_code == 200:
                # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ Gutenberg
                text = response.text
                start_markers = ["*** START OF", "***START OF"]
                end_markers = ["*** END OF", "***END OF"]
                
                for marker in start_markers:
                    if marker in text:
                        text = text.split(marker, 1)[1]
                
                for marker in end_markers:
                    if marker in text:
                        text = text.split(marker, 1)[0]
                
                if len(text) > 5000:  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –±–æ–ª—å—à–∏–µ —Ç–µ–∫—Å—Ç—ã
                    filename = natural_dir / f"gutenberg_{book_id}.txt"
                    with open(filename, 'w', encoding='utf-8') as f:
                        f.write(text)
                    
                    downloaded += 1
                    print(f"  ‚úì –ö–Ω–∏–≥–∞ ID {book_id} ({len(text)} chars)")
                    
                    time.sleep(2)  # –£–≤–∞–∂–∞–µ–º —Å–µ—Ä–≤–µ—Ä
                    
        except Exception as e:
            print(f"  ‚úó –û—à–∏–±–∫–∞ —Å –∫–Ω–∏–≥–æ–π {book_id}: {e}")
            continue
    
    return downloaded

def create_sample_natural_texts():
    """–°–æ–∑–¥–∞–Ω–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –µ—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∏–ª–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö"""
    natural_dir = Path('data/raw/natural')
    
    # –ü—Ä–∏–º–µ—Ä—ã –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –Ω–∞ —Ä–∞–∑–Ω—ã–µ —Ç–µ–º—ã
    sample_texts = [
        """Machine learning is a method of data analysis that automates analytical model building. 
        It is a branch of artificial intelligence based on the idea that systems can learn from data, 
        identify patterns and make decisions with minimal human intervention.""",
        
        """Renewable energy is energy that is collected from renewable resources that are naturally 
        replenished on a human timescale. It includes sources like sunlight, wind, rain, tides, 
        waves, and geothermal heat.""",
        
        """Climate change refers to long-term shifts in temperatures and weather patterns. 
        These shifts may be natural, but since the 1800s, human activities have been the main 
        driver of climate change, primarily due to the burning of fossil fuels.""",
        
        """The Internet has revolutionized communication and commerce. It connects billions of 
        devices worldwide and enables instant communication across vast distances.""",
        
        """Python is an interpreted high-level general-purpose programming language. Its design 
        philosophy emphasizes code readability with its use of significant indentation."""
    ]
    
    created = 0
    existing_files = len(list(natural_dir.glob("*.txt")))
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä—ã –ø–æ–∫–∞ –Ω–µ –¥–æ—Å—Ç–∏–≥–Ω–µ–º 100 —Ñ–∞–π–ª–æ–≤
    for i in range(max(0, 100 - existing_files)):
        text = random.choice(sample_texts)
        filename = natural_dir / f"sample_natural_{i}.txt"
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(text)
        created += 1
    
    if created > 0:
        print(f"\nüìù –°–æ–∑–¥–∞–Ω–æ {created} –ø—Ä–∏–º–µ—Ä–æ–≤ –æ–±—ã—á–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤")
    
    return created

if __name__ == "__main__":
    print("üöÄ –ó–ê–ì–†–£–ó–ö–ê –û–ë–´–ß–ù–´–• –¢–ï–ö–°–¢–û–í")
    print("=" * 50)
    
    total_downloaded = 0
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ Wikipedia
    wiki_count = download_wikipedia_articles()
    total_downloaded += wiki_count
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ Project Gutenberg
    gutenberg_count = download_project_gutenberg_books()
    total_downloaded += gutenberg_count
    
    # –î–æ–±–∏—Ä–∞–µ–º –¥–æ 100 —Ñ–∞–π–ª–æ–≤ –ø—Ä–∏–º–µ—Ä–∞–º–∏
    sample_count = create_sample_natural_texts()
    total_downloaded += sample_count
    
    # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    natural_dir = Path('data/raw/natural')
    final_count = len(list(natural_dir.glob("*.txt")))
    
    print(f"\n‚úÖ –ó–ê–í–ï–†–®–ï–ù–û!")
    print(f"üìä –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   Wikipedia —Å—Ç–∞—Ç–µ–π: {wiki_count}")
    print(f"   Gutenberg –∫–Ω–∏–≥: {gutenberg_count}")
    print(f"   –ü—Ä–∏–º–µ—Ä–æ–≤ —Å–æ–∑–¥–∞–Ω–æ: {sample_count}")
    print(f"   –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {final_count}")
    print(f"   –ü–∞–ø–∫–∞: {natural_dir.absolute()}")