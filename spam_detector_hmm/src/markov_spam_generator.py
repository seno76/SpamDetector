"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ —Å–ø–∞–º–∞ —Å –ø–æ–º–æ—â—å—é –º–∞—Ä–∫–æ–≤—Å–∫–∏—Ö —Ü–µ–ø–µ–π
"""
import random
import re
import json
from pathlib import Path
from collections import defaultdict, Counter
import numpy as np

class MarkovSpamGenerator:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ —Å–ø–∞–º–∞"""
    
    def __init__(self, order=2, diversity=0.3):
        self.order = order
        self.diversity = diversity
        self.chain = defaultdict(Counter)
        self.start_words = []
        self.vocab = set()
    
    def train_on_corpus(self, texts):
        """–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –∫–æ—Ä–ø—É—Å–µ —Ç–µ–∫—Å—Ç–æ–≤"""
        print(f"üîß –û–±—É—á–µ–Ω–∏–µ –º–∞—Ä–∫–æ–≤—Å–∫–æ–π —Ü–µ–ø–∏ –Ω–∞ {len(texts)} —Ç–µ–∫—Å—Ç–∞—Ö...")
        
        for text in texts:
            words = self._tokenize_text(text)
            if len(words) < self.order + 1:
                continue
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ä—Ç–æ–≤—ã–µ —Å–ª–æ–≤–∞
            self.start_words.extend(words[:self.order])
            
            # –°—Ç—Ä–æ–∏–º —Ü–µ–ø—å
            for i in range(len(words) - self.order):
                state = tuple(words[i:i + self.order])
                next_word = words[i + self.order]
                
                self.chain[state][next_word] += 1
                self.vocab.add(next_word)
        
        print(f"‚úì –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
        print(f"  –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π: {len(self.chain)}")
        print(f"  –†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è: {len(self.vocab)}")
        print(f"  –°—Ç–∞—Ä—Ç–æ–≤—ã—Ö —Å–ª–æ–≤: {len(self.start_words)}")
    
    def _tokenize_text(self, text):
        """–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º SEO-–ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ SEO-—Å–∏–º–≤–æ–ª—ã
        text = re.sub(r'[!?]+', ' ! ', text)  # –í–æ—Å–∫–ª–∏—Ü–∞–Ω–∏—è
        text = re.sub(r'[%]+', ' % ', text)  # –ü—Ä–æ—Ü–µ–Ω—Ç—ã
        text = re.sub(r'[$]+', ' $ ', text)  # –î–æ–ª–ª–∞—Ä—ã
        
        # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
        words = re.findall(r'\w+|[!%$#@&*()]', text.lower())
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è
        words = [word for word in words if len(word) > 1 or word in '!%$#@&*()']
        
        return words
    
    def generate_spam(self, min_length=15, max_length=50, spam_intensity=0.7):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ø–∞–º-—Ç–µ–∫—Å—Ç–∞"""
        if not self.chain or not self.start_words:
            return "–û–±—É—á–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞ –º–æ–¥–µ–ª—å –Ω–∞ –¥–∞–Ω–Ω—ã—Ö!"
        
        # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω–æ–µ –Ω–∞—á–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        start_idx = random.randint(0, len(self.start_words) - self.order)
        state = tuple(self.start_words[start_idx:start_idx + self.order])
        
        result = list(state)
        current_length = len(result)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
        while current_length < max_length:
            if state in self.chain and random.random() > self.diversity:
                # –í—ã–±–∏—Ä–∞–µ–º —Å–ª–µ–¥—É—é—â–µ–µ —Å–ª–æ–≤–æ –ø–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º
                next_words = list(self.chain[state].keys())
                weights = list(self.chain[state].values())
                
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ—Å–∞
                total = sum(weights)
                probabilities = [w/total for w in weights]
                
                next_word = np.random.choice(next_words, p=probabilities)
            else:
                # –°–ª—É—á–∞–π–Ω–æ–µ —Å–ª–æ–≤–æ –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
                next_word = random.choice(list(self.vocab)) if self.vocab else "spam"
            
            result.append(next_word)
            state = tuple(result[-self.order:])
            current_length += 1
            
            if current_length >= min_length and random.random() < 0.1:
                break
        
        # –ü–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –ø—Ä–∏–¥–∞–Ω–∏—è —Å–ø–∞–º-–≤–∏–¥–∞
        spam_text = self._post_process_text(result, spam_intensity)
        return spam_text
    
    def _post_process_text(self, words, spam_intensity):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–ø–∞–º-–ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∫ —Ç–µ–∫—Å—Ç—É"""
        text = ' '.join(words)
        
        # SEO-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
        if random.random() < spam_intensity:
            seo_patterns = [
                " buy now discount best price free shipping",
                " limited time offer click here win prize",
                " cheap affordable quality guaranteed satisfaction",
                " special promotion exclusive deal today only",
                " order now fast delivery money back guarantee"
            ]
            text += random.choice(seo_patterns)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞–∫–∏
        if random.random() < spam_intensity * 0.5:
            text = text.replace(' ! ', '!!! ')
            if random.random() < 0.3:
                text += "!!!"
        
        # –î–æ–±–∞–≤–ª—è–µ–º CAPS LOCK –¥–ª—è emphasis
        if random.random() < spam_intensity * 0.3:
            words = text.split()
            if len(words) > 3:
                cap_word = random.randint(0, len(words) - 1)
                words[cap_word] = words[cap_word].upper()
                text = ' '.join(words)
        
        return text.capitalize()
    
    def generate_dataset(self, n_samples=100, **kwargs):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å–ø–∞–º-—Ç–µ–∫—Å—Ç–æ–≤"""
        print(f"üîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è {n_samples} —Å–ø–∞–º-—Ç–µ–∫—Å—Ç–æ–≤...")
        
        samples = []
        for i in range(n_samples):
            spam_text = self.generate_spam(**kwargs)
            samples.append(spam_text)
            
            if (i + 1) % 10 == 0:
                print(f"  –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: {i + 1}/{n_samples}", end='\r')
        
        print(f"\n‚úì –î–∞—Ç–∞—Å–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {len(samples)} —Ç–µ–∫—Å—Ç–æ–≤")
        return samples
    
    def save_model(self, path='models/markov_spam_generator.pkl'):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        import joblib
        Path('models').mkdir(exist_ok=True)
        joblib.dump(self, path)
        print(f"‚úì –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {path}")
    
    @classmethod
    def load_model(cls, path='models/markov_spam_generator.pkl'):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏"""
        import joblib
        return joblib.load(path)

def create_markov_spam_dataset():
    """–°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –º–∞—Ä–∫–æ–≤—Å–∫–æ–≥–æ —Å–ø–∞–º–∞"""
    from data_loader import DataLoader
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–ø–∞–º-—Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    _, spam_texts = DataLoader.load_train_data()
    
    if not spam_texts:
        print("‚ö†Ô∏è –ù–µ—Ç —Å–ø–∞–º-—Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è! –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∏–º–µ—Ä—ã...")
        sample_data = DataLoader.load_sample_data()
        spam_texts = sample_data.get('spam', [])
    
    if not spam_texts:
        # –†–µ–∑–µ—Ä–≤–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã
        spam_texts = [
            "buy cheap pills online pharmacy discount best price",
            "win money casino gambling bonus free spins jackpot",
            "make money fast easy work from home earn cash",
            "weight loss pills diet supplement fat burner quick",
            "SEO services optimization ranking google first page"
        ]
    
    # –°–æ–∑–¥–∞–µ–º –∏ –æ–±—É—á–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä
    generator = MarkovSpamGenerator(order=2)
    generator.train_on_corpus(spam_texts)
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–∞—Ç–∞—Å–µ—Ç
    markov_spam_texts = generator.generate_dataset(n_samples=100)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –æ—Ç–¥–µ–ª—å–Ω—É—é –ø–∞–ø–∫—É
    markov_dir = Path('data/raw/markov_spam')
    markov_dir.mkdir(parents=True, exist_ok=True)
    
    for i, text in enumerate(markov_spam_texts):
        with open(markov_dir / f"markov_spam_{i}.txt", 'w', encoding='utf-8') as f:
            f.write(text)
    
    print(f"‚úì –ú–∞—Ä–∫–æ–≤—Å–∫–∏–π —Å–ø–∞–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {markov_dir}")
    return markov_spam_texts

if __name__ == "__main__":
    create_markov_spam_dataset()
