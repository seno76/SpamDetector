"""
–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ —Å–ø–∞–º–∞ —Å –ø–æ–º–æ—â—å—é –º–∞—Ä–∫–æ–≤—Å–∫–∏—Ö —Ü–µ–ø–µ–π
"""
import random
import re
from pathlib import Path

class MarkovSpamGenerator:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ —Å–ø–∞–º–∞ —Å –ø–æ–º–æ—â—å—é –º–∞—Ä–∫–æ–≤—Å–∫–∏—Ö —Ü–µ–ø–µ–π"""
    
    def __init__(self, order=2):
        self.order = order
        self.chain = {}
        self.start_states = []
    
    def train_on_keywords(self, keywords_file):
        """–û–±—É—á–∞–µ–º –Ω–∞ SEO-–∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤–∞—Ö"""
        try:
            with open(keywords_file, 'r', encoding='utf-8') as f:
                keywords = [line.strip() for line in f if line.strip()]
        except FileNotFoundError:
            print(f"‚ö†Ô∏è –§–∞–π–ª {keywords_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return False
        
        # –°—Ç—Ä–æ–∏–º –º–∞—Ä–∫–æ–≤—Å–∫—É—é —Ü–µ–ø—å
        for phrase in keywords:
            words = self._clean_and_split(phrase)
            if len(words) < self.order + 1:
                continue
                
            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ä—Ç–æ–≤—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
            self.start_states.append(tuple(words[:self.order]))
            
            for i in range(len(words) - self.order):
                state = tuple(words[i:i + self.order])
                next_word = words[i + self.order]
                
                if state not in self.chain:
                    self.chain[state] = []
                self.chain[state].append(next_word)
        
        print(f"‚úì –ü–æ—Å—Ç—Ä–æ–µ–Ω–∞ –º–∞—Ä–∫–æ–≤—Å–∫–∞—è —Ü–µ–ø—å –ø–æ—Ä—è–¥–∫–∞ {self.order}")
        print(f"  –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π: {len(self.chain)}")
        print(f"  –°—Ç–∞—Ä—Ç–æ–≤—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π: {len(self.start_states)}")
        return True
    
    def _clean_and_split(self, text):
        """–û—á–∏—Å—Ç–∫–∞ –∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Å–ª–æ–≤–∞"""
        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ —Ä–∞–∑–¥–µ–ª—è–µ–º
        text = re.sub(r'\s+', ' ', text.strip())
        return text.split()
    
    def generate_spam(self, length=50, diversity=0.3):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–π —Å–ø–∞–º"""
        if not self.chain or not self.start_states:
            return "–ú–∞—Ä–∫–æ–≤—Å–∫–∞—è —Ü–µ–ø—å –Ω–µ –æ–±—É—á–µ–Ω–∞"
        
        # –ù–∞—á–∏–Ω–∞–µ–º —Å–æ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        state = random.choice(self.start_states)
        result = list(state)
        
        for _ in range(length):
            if state in self.chain and random.random() > diversity:
                # –°–ª–µ–¥—É–µ–º —Ü–µ–ø–∏
                next_word = random.choice(self.chain[state])
                result.append(next_word)
                state = tuple(result[-self.order:])
            else:
                # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è - —Å–ª—É—á–∞–π–Ω–æ–µ —Å–ª–æ–≤–æ –∏–∑ —Ü–µ–ø–∏
                if self.chain:
                    random_state = random.choice(list(self.chain.keys()))
                    if self.chain[random_state]:
                        next_word = random.choice(self.chain[random_state])
                        result.append(next_word)
                        state = tuple(result[-self.order:])
                    else:
                        break
                else:
                    break
        
        generated_text = " ".join(result)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–∞–º-–ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ—Å—Ç–∏
        if random.random() > 0.5:
            spam_patterns = [
                " –∫—É–ø–∏—Ç—å —Å–æ —Å–∫–∏–¥–∫–æ–π –∞–∫—Ü–∏—è –±–µ—Å–ø–ª–∞—Ç–Ω–æ",
                " –¥–æ—Å—Ç–∞–≤–∫–∞ –ø–æ –≤—Å–µ–π –†–æ—Å—Å–∏–∏ —Å–∫–∏–¥–∫–∏",
                " –ª—É—á—à–∞—è —Ü–µ–Ω–∞ –≥–∞—Ä–∞–Ω—Ç–∏—è –∫–∞—á–µ—Å—Ç–≤–∞",
                " —Å–∫–∏–¥–∫–∏ –¥–æ 50% —Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∞",
                " –±–µ—Å–ø–ª–∞—Ç–Ω–∞—è –¥–æ—Å—Ç–∞–≤–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∞"
            ]
            generated_text += random.choice(spam_patterns)
        
        return generated_text
    
    def generate_multiple_spam(self, count=10, min_length=30, max_length=100):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–ø–∞–º-—Ç–µ–∫—Å—Ç–æ–≤"""
        texts = []
        for i in range(count):
            length = random.randint(min_length, max_length)
            text = self.generate_spam(length=length)
            texts.append(text)
        return texts

def create_seo_keywords_file():
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ —Å SEO-–∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏"""
    keywords = [
        "–∫—É–ø–∏—Ç—å –∫–≤–∞—Ä—Ç–∏—Ä–∞ –ú–æ—Å–∫–≤–∞ –Ω–µ–¥–æ—Ä–æ–≥–æ",
        "–∑–∞–∫–∞–∑–∞—Ç—å –ø–∏—Ü—Ü–∞ –¥–æ—Å—Ç–∞–≤–∫–∞ –±—ã—Å—Ç—Ä–æ",
        "—Å–∫–∞—á–∞—Ç—å —Ñ–∏–ª—å–º –±–µ—Å–ø–ª–∞—Ç–Ω–æ –±–µ–∑ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏",
        "–æ–Ω–ª–∞–π–Ω –∫–∞–∑–∏–Ω–æ –±–æ–Ω—É—Å –∑–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é",
        "–∫—É—Ä—Å—ã –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞ –æ–±—É—á–µ–Ω–∏–µ",
        "—Ä–µ–º–æ–Ω—Ç iPhone –±—ã—Å—Ç—Ä–æ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ",
        "—Ç—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—É—Ç–µ–≤–∫–∏ –≥–æ—Ä—è—â–∏–µ —Ç—É—Ä—ã",
        "–∫—Ä–µ–¥–∏—Ç –Ω–∞–ª–∏—á–Ω—ã–º–∏ —Å—Ä–æ—á–Ω–æ –≤—ã–≥–æ–¥–Ω–æ",
        "—Ä–∞–±–æ—Ç–∞ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ –±–µ–∑ –≤–ª–æ–∂–µ–Ω–∏–π",
        "–ø–æ—Ö—É–¥–µ–Ω–∏–µ –∑–∞ –Ω–µ–¥–µ–ª—é –±—ã—Å—Ç—Ä–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ",
        "–∫—É–ø–∏—Ç—å –∞–≤—Ç–æ–º–æ–±–∏–ª—å —Å –ø—Ä–æ–±–µ–≥–æ–º",
        "–∑–∞–ø–∏—Å—å –∫ –≤—Ä–∞—á—É –æ–Ω–ª–∞–π–Ω",
        "–¥–æ—Å—Ç–∞–≤–∫–∞ –µ–¥—ã —Ä–µ—Å—Ç–æ—Ä–∞–Ω—ã",
        "—Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ –¥–æ–º–æ–≤ –ø–æ–¥ –∫–ª—é—á",
        "–æ–±—É—á–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é —Å –Ω—É–ª—è",
        "–∫—É–ø–∏—Ç—å –Ω–æ—É—Ç–±—É–∫ –Ω–µ–¥–æ—Ä–æ–≥–æ –ú–æ—Å–∫–≤–∞",
        "–∑–∞–∫–∞–∑ —Ç–∞–∫—Å–∏ –Ω–µ–¥–æ—Ä–æ–≥–æ –±—ã—Å—Ç—Ä–æ",
        "—É—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–∫–æ–Ω –ø–ª–∞—Å—Ç–∏–∫–æ–≤—ã–µ –æ–∫–Ω–∞",
        "—Ä–µ–º–æ–Ω—Ç –∫–≤–∞—Ä—Ç–∏—Ä –ø–æ–¥ –∫–ª—é—á",
        "—É—Å–ª—É–≥–∏ –∫–ª–∏–Ω–∏–Ω–≥–∞ —É–±–æ—Ä–∫–∞ –∫–≤–∞—Ä—Ç–∏—Ä"
    ]
    
    Path('data').mkdir(exist_ok=True)
    with open('data/seo_keywords.txt', 'w', encoding='utf-8') as f:
        for keyword in keywords:
            f.write(keyword + '\n')
    
    print("‚úì –°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª —Å SEO-–∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏")
    return 'data/seo_keywords.txt'

# –£–ë–ò–†–ê–ï–ú –∫–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ
# if __name__ == "__main__":
#     # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞
#     generator = MarkovSpamGenerator(order=2)
#     keywords_file = create_seo_keywords_file()
#     generator.train_on_keywords(keywords_file)
#     
#     print("\nüîç –ü—Ä–∏–º–µ—Ä—ã —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–ø–∞–º–∞:")
#     for i in range(3):
#         spam_text = generator.generate_spam(length=40)
#         print(f"{i+1}. {spam_text}")