"""
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
"""
from pathlib import Path
import sys
sys.path.insert(0, str(Path(__file__).parent / 'src'))

from download_data import create_directories, create_sample_data
from download_natural_texts import download_wikipedia_articles, download_project_gutenberg_books
from download_spam_texts import download_sms_spam_collection, download_email_spam, generate_seo_spam
from src.markov_spam_generator import create_markov_spam_dataset
from src.data_loader import DataLoader

def prepare_all_datasets():
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö"""
    print("üöÄ –ü–û–î–ì–û–¢–û–í–ö–ê –ü–û–õ–ù–û–ì–û –î–ê–¢–ê–°–ï–¢–ê")
    print("="*50)
    
    # 1. –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫
    create_directories()
    
    # 2. –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—ã—á–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã
    print("\nüìö –ó–ê–ì–†–£–ó–ö–ê –û–ë–´–ß–ù–´–• –¢–ï–ö–°–¢–û–í")
    print("-"*30)
    
    wiki_count = download_wikipedia_articles()
    gutenberg_count = download_project_gutenberg_books()
    
    # 3. –ó–∞–≥—Ä—É–∂–∞–µ–º —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–π —Å–ø–∞–º
    print("\nüìß –ó–ê–ì–†–£–ó–ö–ê –ß–ï–õ–û–í–ï–ß–ï–°–ö–û–ì–û –°–ü–ê–ú–ê")
    print("-"*30)
    
    sms_count = download_sms_spam_collection()
    email_count = download_email_spam()
    seo_count = generate_seo_spam()
    
    # 4. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –º–∞—Ä–∫–æ–≤—Å–∫–∏–π —Å–ø–∞–º
    print("\nü§ñ –ì–ï–ù–ï–†–ê–¶–ò–Ø –ú–ê–†–ö–û–í–°–ö–û–ì–û –°–ü–ê–ú–ê")
    print("-"*30)
    
    markov_texts = create_markov_spam_dataset()
    
    # 5. –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if wiki_count + gutenberg_count < 10:
        print("\nüìù –°–û–ó–î–ê–ù–ò–ï –ü–†–ò–ú–ï–†–û–í")
        print("-"*30)
        create_sample_data()
    
    # 6. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\nüìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("="*50)
    
    datasets = DataLoader.get_available_datasets()
    for name, count in datasets.items():
        print(f"   {name}: {count} —Ç–µ–∫—Å—Ç–æ–≤")
    
    total_texts = sum(datasets.values())
    print(f"   –í–°–ï–ì–û: {total_texts} —Ç–µ–∫—Å—Ç–æ–≤")
    
    print("\n‚úÖ –ü–û–î–ì–û–¢–û–í–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!")
    return datasets

if __name__ == "__main__":
    prepare_all_datasets()
